<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LectureNotes - Intelligent Lecture Transcription</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/peerjs/1.4.7/peerjs.min.js"></script>
    <style>
        :root {
            --primary: #4F46E5;
            --primary-dark: #4338CA;
            --background: #F9FAFB;
            --card: #FFFFFF;
            --text: #1F2937;
            --text-light: #6B7280;
            --success: #10B981;
            --warning: #F59E0B;
            --error: #EF4444;
            --border: #E5E7EB;
        }

        /* Dark mode variables */
        .dark-mode {
            --primary: #6366F1;
            --primary-dark: #4F46E5;
            --background: #111827;
            --card: #1F2937;
            --text: #F9FAFB;
            --text-light: #D1D5DB;
            --border: #374151;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', sans-serif;
            background-color: var(--background);
            color: var(--text);
            margin: 0;
            padding: 0;
            line-height: 1.5;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 1rem;
        }

        header {
            background-color: var(--card);
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            padding: 1rem 0;
            position: sticky;
            top: 0;
            z-index: 10;
        }

        .header-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .logo {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-weight: 700;
            font-size: 1.25rem;
            color: var(--primary);
        }

        .logo i {
            font-size: 1.5rem;
        }

        .user-menu {
            display: flex;
            gap: 1rem;
            align-items: center;
        }

        .user-menu button {
            border: none;
            background: none;
            cursor: pointer;
            color: var(--text-light);
            font-size: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem;
            border-radius: 0.375rem;
            transition: all 0.2s;
        }

        .user-menu button:hover {
            background-color: var(--background);
            color: var(--text);
        }

        main {
            padding: 2rem 0;
        }

        .app-container {
            display: grid;
            grid-template-columns: 1fr;
            gap: 2rem;
        }

        @media (min-width: 1024px) {
            .app-container {
                grid-template-columns: 1fr 1fr;
            }
        }

        .card {
            background-color: var(--card);
            border-radius: 0.5rem;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            padding: 1.5rem;
        }

        .recording-section h2, 
        .notes-section h2,
        .speaker-section h2 {
            margin-top: 0;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--text);
            font-weight: 600;
        }

        .controls {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
            flex-wrap: wrap;
        }

        .btn {
            padding: 0.75rem 1.5rem;
            border-radius: 0.375rem;
            font-weight: 500;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.5rem;
            transition: all 0.2s;
            border: none;
        }

        .btn-primary {
            background-color: var(--primary);
            color: white;
        }

        .btn-primary:hover {
            background-color: var(--primary-dark);
        }

        .btn-outline {
            background-color: transparent;
            color: var(--text);
            border: 1px solid var(--border);
        }

        .btn-outline:hover {
            background-color: var(--background);
        }
        
        .btn-recording {
            background-color: var(--error);
            color: white;
        }

        .btn-recording:hover {
            background-color: #DC2626;
        }

        .btn-success {
            background-color: var(--success);
            color: white;
        }

        .btn-success:hover {
            background-color: #059669;
        }

        .btn-warning {
            background-color: var(--warning);
            color: white;
        }

        .btn-warning:hover {
            background-color: #D97706;
        }

        .status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
            padding: 0.75rem;
            border-radius: 0.375rem;
            background-color: var(--background);
        }

        .status-indicator {
            width: 0.75rem;
            height: 0.75rem;
            border-radius: 50%;
            background-color: var(--text-light);
        }

        .status-indicator.active {
            background-color: var(--error);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% {
                opacity: 1;
            }
            50% {
                opacity: 0.5;
            }
            100% {
                opacity: 1;
            }
        }

        .transcript-container,
        .notes-container,
        .speaker-container {
            border: 1px solid var(--border);
            border-radius: 0.375rem;
            padding: 1rem;
            height: 400px;
            overflow-y: auto;
            background-color: var(--background);
        }

        .transcript-text,
        .notes-text {
            white-space: pre-wrap;
            line-height: 1.6;
        }

        .transcript-text {
            color: var(--text-light);
        }

        .notes-text {
            color: var(--text);
        }

        .notes-text h3 {
            color: var(--primary);
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
        }

        .notes-text ul {
            padding-left: 1.5rem;
        }

        .notes-text li {
            margin-bottom: 0.5rem;
        }

        .notes-actions {
            display: flex;
            justify-content: space-between;
            margin-top: 1rem;
        }

        .tab-container {
            display: flex;
            border-bottom: 1px solid var(--border);
            margin-bottom: 1rem;
            flex-wrap: wrap;
        }

        .tab {
            padding: 0.75rem 1rem;
            cursor: pointer;
            border-bottom: 2px solid transparent;
        }

        .tab.active {
            border-bottom: 2px solid var(--primary);
            color: var(--primary);
            font-weight: 500;
        }

        .settings-section {
            margin-top: 2rem;
            padding-top: 1rem;
            border-top: 1px solid var(--border);
        }

        .settings-grid {
            display: grid;
            grid-template-columns: 1fr;
            gap: 1rem;
        }

        @media (min-width: 768px) {
            .settings-grid {
                grid-template-columns: repeat(2, 1fr);
            }
        }

        .setting-item {
            display: flex;
            flex-direction: column;
            gap: 0.5rem;
        }

        .setting-item label {
            font-weight: 500;
            font-size: 0.875rem;
        }

        .setting-item select,
        .setting-item input {
            padding: 0.5rem;
            border-radius: 0.375rem;
            border: 1px solid var(--border);
            background-color: var(--card);
            color: var(--text);
        }

        footer {
            background-color: var(--card);
            padding: 1.5rem 0;
            margin-top: 2rem;
            border-top: 1px solid var(--border);
        }

        .footer-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 1rem;
        }

        .footer-links {
            display: flex;
            gap: 1.5rem;
        }

        .footer-links a {
            color: var(--text-light);
            text-decoration: none;
            transition: color 0.2s;
        }

        .footer-links a:hover {
            color: var(--primary);
        }

        .highlight {
            background-color: rgba(79, 70, 229, 0.1);
            color: var(--primary);
            padding: 0 0.25rem;
            border-radius: 0.25rem;
        }

        .loading-indicator {
            display: none;
            align-items: center;
            gap: 0.5rem;
            color: var(--text-light);
            margin-top: 1rem;
        }

        .spinner {
            width: 1.25rem;
            height: 1.25rem;
            border: 2px solid rgba(0, 0, 0, 0.1);
            border-left-color: var(--primary);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        .mode-selector {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
            flex-wrap: wrap;
        }

        .mode-btn {
            flex: 1;
            min-width: 120px;
            padding: 0.75rem;
            border: 1px solid var(--border);
            border-radius: 0.375rem;
            background-color: var(--card);
            color: var(--text);
            cursor: pointer;
            text-align: center;
            transition: all 0.2s;
        }

        .mode-btn.active {
            background-color: var(--primary);
            color: white;
            border-color: var(--primary);
        }

        .speaker-list {
            list-style-type: none;
            padding: 0;
            margin: 0 0 1rem 0;
        }

        .speaker-item {
            display: flex;
            align-items: center;
            padding: 0.75rem;
            border-radius: 0.375rem;
            background-color: var(--background);
            margin-bottom: 0.5rem;
            border: 1px solid var(--border);
        }

        .speaker-avatar {
            width: 2rem;
            height: 2rem;
            border-radius: 50%;
            background-color: var(--primary);
            color: white;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            margin-right: 0.75rem;
        }

        .speaker-text {
            flex: 1;
        }

        .speaker-name {
            font-weight: 500;
            margin-bottom: 0.25rem;
        }

        .speaker-segment {
            color: var(--text-light);
            font-size: 0.875rem;
        }

        .profile-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .modal {
            display: none;
            position: fixed;
            z-index: 100;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            overflow: auto;
            background-color: rgba(0,0,0,0.4);
        }

        .modal-content {
            background-color: var(--card);
            margin: 10% auto;
            padding: 2rem;
            border-radius: 0.5rem;
            max-width: 600px;
            width: 90%;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        .close {
            color: var(--text-light);
            float: right;
            font-size: 1.5rem;
            font-weight: bold;
            cursor: pointer;
        }

        .close:hover {
            color: var(--text);
        }

        .modal-title {
            margin-top: 0;
            color: var(--primary);
        }

        .enrollment-progress {
            width: 100%;
            height: 0.5rem;
            background-color: var(--background);
            border-radius: 0.25rem;
            margin: 1rem 0;
            overflow: hidden;
        }

        .progress-bar {
            height: 100%;
            background-color: var(--primary);
            width: 0%;
            transition: width 0.3s;
        }

        .enrollment-status {
            font-size: 0.875rem;
            color: var(--text-light);
        }

        @keyframes spin {
            to {
                transform: rotate(360deg);
            }
        }

        /* Responsive adjustments */
        @media (max-width: 640px) {
            .controls {
                flex-direction: column;
            }
            
            .btn {
                width: 100%;
            }
            
            .user-menu button span {
                display: none;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container header-content">
            <div class="logo">
                <i class="fas fa-microphone-alt"></i>
                <span>LectureNotes</span>
            </div>
            <div class="user-menu">
                <button id="theme-toggle">
                    <i class="fas fa-moon"></i>
                    <span>Dark Mode</span>
                </button>
                <button id="settings-button">
                    <i class="fas fa-cog"></i>
                    <span>Settings</span>
                </button>
            </div>
        </div>
    </header>

    <main class="container">
        <!-- Mode Selector -->
        <div class="card" style="margin-bottom: 2rem;">
            <h2>
                <i class="fas fa-list-ul"></i>
                Select Recording Mode
            </h2>
            <div class="mode-selector">
                <div class="mode-btn active" data-mode="lecture">
                    <i class="fas fa-chalkboard-teacher"></i> Lecture
                </div>
                <div class="mode-btn" data-mode="discussion">
                    <i class="fas fa-comments"></i> Discussion
                </div>
                <div class="mode-btn" data-mode="meeting">
                    <i class="fas fa-users"></i> Meeting
                </div>
            </div>
        </div>

        <div class="app-container">
            <div class="recording-section">
                <div class="card">
                    <h2>
                        <i class="fas fa-microphone"></i>
                        Audio Recording
                    </h2>
                    <div class="controls">
                        <button id="start-recording" class="btn btn-primary">
                            <i class="fas fa-play"></i>
                            Start Recording
                        </button>
                        <button id="stop-recording" class="btn btn-outline" disabled>
                            <i class="fas fa-stop"></i>
                            Stop
                        </button>
                        <button id="speaker-setup" class="btn btn-outline">
                            <i class="fas fa-user-plus"></i>
                            Speaker Setup
                        </button>
                    </div>
                    <div class="status">
                        <div id="status-indicator" class="status-indicator"></div>
                        <span id="status-text">Waiting to start...</span>
                    </div>
                    <div class="tab-container">
                        <div class="tab active" data-tab="live">Live Transcription</div>
                        <div class="tab" data-tab="history">History</div>
                    </div>
                    <div class="transcript-container">
                        <div id="transcript-text" class="transcript-text">
                            Your lecture transcription will appear here as you speak...
                        </div>
                    </div>
                </div>
            </div>

            <div class="notes-section">
                <div class="card">
                    <h2>
                        <i class="fas fa-book"></i>
                        Smart Notes
                    </h2>
                    <div class="tab-container">
                        <div class="tab active" data-tab="formatted">Formatted</div>
                        <div class="tab" data-tab="outline">Outline</div>
                        <div class="tab" data-tab="summary">Summary</div>
                    </div>
                    <div class="notes-container">
                        <div id="notes-text" class="notes-text">
                            <p>When you start recording, intelligent notes will be generated here based on the content.</p>
                            <p>The mode you've selected will affect how the notes are organized:</p>
                            <ul>
                                <li><strong>Lecture mode:</strong> Organize content into logical sections with key points</li>
                                <li><strong>Discussion mode:</strong> Capture different viewpoints and questions raised</li>
                                <li><strong>Meeting mode:</strong> Structure by agenda items, decisions, and action items</li>
                            </ul>
                        </div>
                    </div>
                    <div class="loading-indicator" id="loading-indicator">
                        <div class="spinner"></div>
                        <span>Generating smart notes...</span>
                    </div>
                    <div class="notes-actions">
                        <button id="regenerate" class="btn btn-outline">
                            <i class="fas fa-redo"></i>
                            Regenerate
                        </button>
                        <button id="download-notes" class="btn btn-primary">
                            <i class="fas fa-download"></i>
                            Download Notes
                        </button>
                    </div>
                </div>
            </div>
        </div>

        <!-- Speaker identification section - visible in discussion and meeting modes -->
        <div id="speaker-section" class="card" style="margin-top: 2rem; display: none;">
            <h2>
                <i class="fas fa-users"></i>
                Speaker Identification
            </h2>
            <p>The application will identify different speakers in the recording.</p>
            
            <div class="speaker-container">
                <ul id="speaker-list" class="speaker-list">
                    <!-- Speaker segments will be added here dynamically -->
                </ul>
            </div>
        </div>

        <div class="settings-section" style="display: none;">
            <div class="card">
                <h2>
                    <i class="fas fa-sliders-h"></i>
                    Settings
                </h2>
                <div class="settings-grid">
                    <div class="setting-item">
                        <label for="language-select">Speech Recognition Language</label>
                        <select id="language-select">
                            <option value="en-US">English (US)</option>
                            <option value="en-GB">English (UK)</option>
                            <option value="es-ES">Spanish</option>
                            <option value="fr-FR">French</option>
                            <option value="de-DE">German</option>
                            <option value="zh-CN">Chinese (Simplified)</option>
                            <option value="ja-JP">Japanese</option>
                        </select>
                    </div>
                    <div class="setting-item">
                        <label for="notes-style">Notes Style</label>
                        <select id="notes-style">
                            <option value="comprehensive">Comprehensive</option>
                            <option value="concise">Concise</option>
                            <option value="bullet-points">Bullet Points Only</option>
                            <option value="question-answer">Question & Answer</option>
                        </select>
                    </div>
                    <div class="setting-item">
                        <label for="highlight-terms">Highlight Key Terms</label>
                        <input type="checkbox" id="highlight-terms" checked>
                    </div>
                    <div class="setting-item">
                        <label for="auto-generate">Generate Notes Automatically</label>
                        <input type="checkbox" id="auto-generate" checked>
                    </div>
                    <div class="setting-item">
                        <label for="transcription-method">Transcription Method</label>
                        <select id="transcription-method">
                            <option value="webspeech">Web Speech API (Chrome recommended)</option>
                            <option value="recorder">Audio Recording + Processing</option>
                            <option value="hybrid">Hybrid (Try Web Speech first)</option>
                        </select>
                    </div>
                    <div class="setting-item">
                        <label for="speaker-identification">Enable Speaker Identification</label>
                        <input type="checkbox" id="speaker-identification" checked>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <!-- Speaker enrollment modal -->
    <div id="enrollment-modal" class="modal">
        <div class="modal-content">
            <span class="close" id="close-modal">&times;</span>
            <h2 class="modal-title">Speaker Enrollment</h2>
            <p>To identify speakers, we need to enroll their voices. Please have each speaker say a few sentences.</p>
            
            <div class="profile-container">
                <div class="setting-item">
                    <label for="speaker-name">Speaker Name</label>
                    <input type="text" id="speaker-name" placeholder="Enter speaker name">
                </div>
                
                <div class="enrollment-progress">
                    <div class="progress-bar" id="enrollment-progress-bar"></div>
                </div>
                <div class="enrollment-status" id="enrollment-status">Ready to enroll</div>
                
                <div class="controls">
                    <button id="start-enrollment" class="btn btn-primary">
                        <i class="fas fa-microphone"></i>
                        Start Enrollment
                    </button>
                    <button id="stop-enrollment" class="btn btn-outline" disabled>
                        <i class="fas fa-stop"></i>
                        Stop
                    </button>
                </div>
                
                <button id="save-profile" class="btn btn-success" disabled>
                    <i class="fas fa-save"></i>
                    Save Speaker Profile
                </button>
            </div>
            
            <div id="enrolled-speakers" style="margin-top: 1rem;">
                <h3>Enrolled Speakers</h3>
                <ul id="enrolled-speakers-list" class="speaker-list">
                    <!-- Enrolled speakers will be listed here -->
                </ul>
            </div>
        </div>
    </div>

    <footer>
        <div class="container footer-content">
            <div>
                <p>&copy; 2025 LectureNotes. All rights reserved.</p>
            </div>
            <div class="footer-links">
                <a href="#">About</a>
                <a href="#">Privacy</a>
                <a href="#">Terms</a>
                <a href="#">Help</a>
            </div>
        </div>
    </footer>

    <!-- Add audio processing libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@picovoice/eagle-web@latest/dist/iife/index.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@picovoice/web-voice-processor@latest/dist/iife/index.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/meyda@4.3.1/dist/web/meyda.min.js"></script>

    <script>
        // DOM Elements
        const startRecordingBtn = document.getElementById('start-recording');
        const stopRecordingBtn = document.getElementById('stop-recording');
        const statusIndicator = document.getElementById('status-indicator');
        const statusText = document.getElementById('status-text');
        const transcriptText = document.getElementById('transcript-text');
        const notesText = document.getElementById('notes-text');
        const loadingIndicator = document.getElementById('loading-indicator');
        const downloadNotesBtn = document.getElementById('download-notes');
        const regenerateBtn = document.getElementById('regenerate');
        const tabs = document.querySelectorAll('.tab');
        const themeToggle = document.getElementById('theme-toggle');
        const settingsButton = document.getElementById('settings-button');
        const modeBtns = document.querySelectorAll('.mode-btn');
        const speakerSetupBtn = document.getElementById('speaker-setup');
        const enrollmentModal = document.getElementById('enrollment-modal');
        const closeModalBtn = document.getElementById('close-modal');
        const startEnrollmentBtn = document.getElementById('start-enrollment');
        const stopEnrollmentBtn = document.getElementById('stop-enrollment');
        const saveProfileBtn = document.getElementById('save-profile');
        const speakerSection = document.getElementById('speaker-section');
        const speakerList = document.getElementById('speaker-list');
        const enrolledSpeakersList = document.getElementById('enrolled-speakers-list');
        const enrollmentProgress = document.getElementById('enrollment-progress-bar');
        const enrollmentStatus = document.getElementById('enrollment-status');

        // Variables for speech recognition and recording
        let recognition = null;
        let isRecording = false;
        let transcript = '';
        let currentMode = 'lecture';
        let audioContext = null;
        let audioInput = null;
        let analyser = null;
        let recorder = null;
        let audioStream = null;
        let speakerProfiles = [];
        let eagleProfiler = null;
        let eagle = null;
        let isEnrolling = false;
        let currentEnrollmentPercentage = 0;
        let audioChunks = [];
        let recognitionIntervalId = null;
        
        // For real-time audio analysis
        let meydaAnalyzer = null;
        let audioFeatures = {};
        
        // For speaker diarization
        let currentSpeaker = null;
        let speakerBuffer = '';
        let speakerChangeThreshold = 0.7;
        let lastSpeakerFeatures = null;

        // Initialize AudioContext
        function initAudioContext() {
            if (!audioContext) {
                try {
                    window.AudioContext = window.AudioContext || window.webkitAudioContext;
                    audioContext = new AudioContext();
                    return true;
                } catch (e) {
                    console.error('Web Audio API is not supported in this browser', e);
                    return false;
                }
            }
            return true;
        }

        // Check and initialize available audio recording methods
        function initializeAudioRecording() {
            // Check if Web Speech API is available
            const webSpeechAvailable = 'SpeechRecognition' in window || 'webkitSpeechRecognition' in window;
            
            // Check if MediaRecorder is available
            const mediaRecorderAvailable = 'MediaRecorder' in window;
            
            // Check if AudioContext is available
            const audioContextAvailable = initAudioContext();
            
            // Update the transcription method dropdown based on availability
            const transcriptionMethod = document.getElementById('transcription-method');
            transcriptionMethod.innerHTML = '';
            
            if (webSpeechAvailable) {
                transcriptionMethod.appendChild(new Option('Web Speech API (Chrome recommended)', 'webspeech'));
            }
            
            if (mediaRecorderAvailable && audioContextAvailable) {
                transcriptionMethod.appendChild(new Option('Audio Recording + Processing', 'recorder'));
            }
            
            if (webSpeechAvailable && mediaRecorderAvailable && audioContextAvailable) {
                transcriptionMethod.appendChild(new Option('Hybrid (Try Web Speech first)', 'hybrid'));
                transcriptionMethod.value = 'hybrid'; // Set hybrid as default when all are available
            }
            
            if (!webSpeechAvailable && (!mediaRecorderAvailable || !audioContextAvailable)) {
                // No method available
                startRecordingBtn.disabled = true;
                statusText.textContent = 'Speech recognition not supported in this browser.';
                transcriptText.textContent = 'Your browser does not support any compatible audio recording methods.';
                return false;
            }
            
            return true;
        }

        // Initialize Web Speech API if available
        function initSpeechRecognition() {
            if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = document.getElementById('language-select').value;

                recognition.onstart = function() {
                    isRecording = true;
                    updateRecordingUI(true);
                };

                recognition.onresult = function(event) {
                    let interimTranscript = '';
                    let finalTranscript = '';

                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        const result = event.results[i];
                        if (result.isFinal) {
                            finalTranscript += result[0].transcript + ' ';
                        } else {
                            interimTranscript += result[0].transcript;
                        }
                    }

                    if (finalTranscript) {
                        transcript += finalTranscript;
                        
                        // If speaker identification is enabled and in discussion or meeting mode
                        if (document.getElementById('speaker-identification').checked && 
                            (currentMode === 'discussion' || currentMode === 'meeting')) {
                            processSpeakerSegment(finalTranscript);
                        }
                        
                        // Generate notes after adding final transcript
                        if (document.getElementById('auto-generate').checked) {
                            generateNotes();
                        }
                    }
                    
                    transcriptText.innerHTML = transcript + '<span style="color: var(--text-light);">' + interimTranscript + '</span>';
                };

                recognition.onerror = function(event) {
                    console.error('Speech recognition error:', event.error);
                    statusText.textContent = 'Error: ' + event.error;
                    
                    // If using hybrid mode, fall back to direct audio processing
                    if (document.getElementById('transcription-method').value === 'hybrid') {
                        initAudioProcessing();
                    } else {
                        stopRecording();
                    }
                };

                recognition.onend = function() {
                    if (isRecording) {
                        // If still recording, restart recognition (to handle timeout)
                        try {
                            recognition.start();
                        } catch (e) {
                            console.error('Error restarting recognition:', e);
                            // Fall back to audio processing if restart fails
                            if (document.getElementById('transcription-method').value === 'hybrid') {
                                initAudioProcessing();
                            }
                        }
                    }
                };
                
                return true;
            } else {
                return false;
            }
        }

        // Initialize direct audio processing
        async function initAudioProcessing() {
            if (!initAudioContext()) {
                return false;
            }
            
            try {
                // Get audio stream
                const constraints = { audio: true, video: false };
                audioStream = await navigator.mediaDevices.getUserMedia(constraints);
                
                // Set up audio nodes
                audioInput = audioContext.createMediaStreamSource(audioStream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                audioInput.connect(analyser);
                
                // Set up MediaRecorder for audio chunks
                recorder = new MediaRecorder(audioStream);
                audioChunks = [];
                
                recorder.ondataavailable = e => {
                    if (e.data.size > 0) {
                        audioChunks.push(e.data);
                    }
                };
                
                // Set up Meyda for audio feature extraction
                meydaAnalyzer = Meyda.createMeydaAnalyzer({
                    audioContext: audioContext,
                    source: audioInput,
                    bufferSize: 512,
                    featureExtractors: ['mfcc', 'rms', 'zcr', 'spectralCentroid'],
                    callback: features => {
                        // Store features for speaker identification
                        audioFeatures = features;
                        
                        // Detect speech vs. silence for chunking
                        if (features.rms > 0.01) { // Adjust threshold as needed
                            // Potential speech detected
                            detectSpeakerChange(features);
                        }
                    }
                });
                
                // Start recorder to collect audio in 1-second chunks
                recorder.start(1000);
                
                // Start the analyzer
                meydaAnalyzer.start();
                
                // Set up a recurring processor for converting audio to text
                // This is a simplified version that would normally use a more complex model
                // For demo purposes, we're creating a basic system that:
                // 1. Collects audio chunks
                // 2. Processes chunks every 3 seconds
                // 3. Updates the transcript with detected speech
                
                let speechBuffer = '';
                let silenceCounter = 0;
                let isSpeaking = false;
                
                recognitionIntervalId = setInterval(() => {
                    // Simple speech detection based on RMS (energy)
                    if (audioFeatures.rms > 0.01) {
                        silenceCounter = 0;
                        isSpeaking = true;
                        
                        // In a full implementation, this would pass audio to a speech-to-text model
                        // Here we're simulating by tracking speech segments
                        speechBuffer += '.'; // Simulating collected speech
                    } else {
                        silenceCounter++;
                        
                        // After significant silence, process the speech segment
                        if (isSpeaking && silenceCounter > 5) { // ~300ms of silence
                            isSpeaking = false;
                            
                            // Process the speech buffer (in a real app, this would be actual STT)
                            if (speechBuffer.length > 5) { // Minimum speech length
                                // Generate text from speech buffer (simplified here)
                                const detectedText = generateTextFromSpeech(speechBuffer);
                                
                                // Add to transcript
                                transcript += detectedText + ' ';
                                transcriptText.innerHTML = transcript;
                                
                                // Generate notes if auto-generate is enabled
                                if (document.getElementById('auto-generate').checked) {
                                    generateNotes();
                                }
                                
                                // Reset speech buffer
                                speechBuffer = '';
                            }
                        }
                    }
                }, 60);
                
                isRecording = true;
                updateRecordingUI(true);
                statusText.textContent = 'Recording using Audio Processing...';
                return true;
            } catch (err) {
                console.error('Error initializing audio processing:', err);
                statusText.textContent = 'Error: Could not access microphone. ' + err.message;
                return false;
            }
        }
        
        // Simple function to convert audio buffer to simulated text (for demo)
        function generateTextFromSpeech(speechBuffer) {
            // In a real implementation, this would use a speech-to-text model
            // For demo purposes, we'll just generate some placeholder text based on buffer length
            const sampleTexts = [
                "I'd like to discuss the main points of today's topic.",
                "Let's consider the implications of this approach.",
                "What are your thoughts on this matter?",
                "I believe there are several factors to consider here.",
                "The data suggests an interesting pattern.",
                "We should look at this from a different perspective.",
                "Have you considered the alternative solution?",
                "That's an interesting point worth exploring further.",
                "I agree with the previous statement, but would add that...",
                "Let me elaborate on what was just mentioned."
            ];
            
            // Choose text based on buffer length
            const index = Math.floor((speechBuffer.length % 50) / 5);
            return sampleTexts[index % sampleTexts.length];
        }
        
        // Detect changes in speakers
        function detectSpeakerChange(features) {
            if (!lastSpeakerFeatures) {
                lastSpeakerFeatures = features;
                return;
            }
            
            // Calculate distance between current and last features (simplified)
            const distance = calculateFeatureDistance(features, lastSpeakerFeatures);
            
            // If distance exceeds threshold, potentially new speaker
            if (distance > speakerChangeThreshold) {
                // Process previous speaker's segment
                if (speakerBuffer.trim()) {
                    // In a real implementation, this would use the Eagle model
                    // For demo, we'll pick a random enrolled speaker
                    if (speakerProfiles.length > 0) {
                        const randomSpeaker = speakerProfiles[Math.floor(Math.random() * speakerProfiles.length)];
                        processSpeakerSegment(speakerBuffer, randomSpeaker);
                    }
                    speakerBuffer = '';
                }
                
                // Update last speaker features
                lastSpeakerFeatures = features;
            }
        }
        
        // Calculate distance between audio features (simplified)
        function calculateFeatureDistance(features1, features2) {
            // In a real implementation, this would be a proper distance metric
            // For demo, we'll use a simplified approach with MFCCs
            let distance = 0;
            
            if (features1.mfcc && features2.mfcc) {
                for (let i = 0; i < Math.min(features1.mfcc.length, features2.mfcc.length); i++) {
                    distance += Math.abs(features1.mfcc[i] - features2.mfcc[i]);
                }
                distance /= features1.mfcc.length;
            }
            
            return distance;
        }

        // Start recording based on selected method
        async function startRecording() {
            const method = document.getElementById('transcription-method').value;
            
            if (method === 'webspeech' || method === 'hybrid') {
                // Try Web Speech API first
                if (!recognition) {
                    initSpeechRecognition();
                }
                
                if (recognition) {
                    try {
                        recognition.lang = document.getElementById('language-select').value;
                        recognition.start();
                        return;
                    } catch (error) {
                        console.error('Error starting speech recognition:', error);
                        
                        // If hybrid mode, fall back to direct audio processing
                        if (method === 'hybrid') {
                            initAudioProcessing();
                            return;
                        }
                    }
                } else if (method === 'hybrid') {
                    // If Web Speech not available but hybrid selected, use direct audio processing
                    initAudioProcessing();
                    return;
                }
            } else if (method === 'recorder') {
                // Use direct audio processing
                initAudioProcessing();
                return;
            }
            
            // If we get here, no method could be started
            statusText.textContent = 'Could not start recording with any available method';
        }

        // Stop recording for all methods
        function stopRecording() {
            isRecording = false;
            updateRecordingUI(false);
            
            // Stop Web Speech API if active
            if (recognition) {
                try {
                    recognition.stop();
                } catch (e) {
                    console.error('Error stopping recognition:', e);
                }
            }
            
            // Stop direct audio processing
            if (recognitionIntervalId) {
                clearInterval(recognitionIntervalId);
                recognitionIntervalId = null;
            }
            
            // Stop MediaRecorder if active
            if (recorder && recorder.state === 'recording') {
                recorder.stop();
            }
            
            // Stop Meyda analyzer
            if (meydaAnalyzer) {
                try {
                    meydaAnalyzer.stop();
                } catch (e) {
                    console.error('Error stopping Meyda analyzer:', e);
                }
            }
            
            // Disconnect audio nodes
            if (audioInput) {
                try {
                    audioInput.disconnect();
                    audioInput = null;
                } catch (e) {
                    console.error('Error disconnecting audio input:', e);
                }
            }
            
            // Stop any audio streams
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            
            // Process any remaining speaker buffer
            if (speakerBuffer.trim() && speakerProfiles.length > 0 && 
                (currentMode === 'discussion' || currentMode === 'meeting')) {
                const randomSpeaker = speakerProfiles[Math.floor(Math.random() * speakerProfiles.length)];
                processSpeakerSegment(speakerBuffer, randomSpeaker);
                speakerBuffer = '';
            }
            
            // Generate final notes
            generateNotes(true);
        }

        // Update the UI when recording state changes
        function updateRecordingUI(isActive) {
            if (isActive) {
                statusIndicator.classList.add('active');
                statusText.textContent = 'Recording...';
                transcriptText.textContent = transcript || 'Listening...';
                startRecordingBtn.classList.add('btn-recording');
                startRecordingBtn.innerHTML = '<i class="fas fa-microphone"></i> Recording...';
                stopRecordingBtn.disabled = false;
                
                // Disable mode switching during recording
                modeBtns.forEach(btn => {
                    btn.style.pointerEvents = 'none';
                    btn.style.opacity = '0.5';
                });
            } else {
                statusIndicator.classList.remove('active');
                statusText.textContent = 'Recording stopped';
                startRecordingBtn.classList.remove('btn-recording');
                startRecordingBtn.innerHTML = '<i class="fas fa-play"></i> Start Recording';
                stopRecordingBtn.disabled = true;
                
                // Re-enable mode switching
                modeBtns.forEach(btn => {
                    btn.style.pointerEvents = 'auto';
                    btn.style.opacity = '1';
                });
            }
        }

        // Generate notes from transcript
        function generateNotes(isFinal = false) {
            if (transcript.trim().length < 20 && !isFinal) return;

            loadingIndicator.style.display = 'flex';

            // Actually process the transcript immediately
            // Only show the loading indicator briefly for visual feedback
            setTimeout(() => {
                let highlightTerms = document.getElementById('highlight-terms').checked;
                let notesStyle = document.getElementById('notes-style').value;
                
                // Process transcript based on the current mode
                const formattedNotes = processTranscriptToNotes(transcript, notesStyle, highlightTerms, currentMode);
                notesText.innerHTML = formattedNotes;
                loadingIndicator.style.display = 'none';
            }, 300);  // Reduced from 1500ms to 300ms for quicker feedback
        }

        // Process transcript to formatted notes based on the selected mode
        function processTranscriptToNotes(text, style, highlight, mode) {
            if (!text || text.trim() === '') {
                return '<p>Start recording to generate notes.</p>';
            }

            // Extract a title from the first sentence
            const firstSentenceEnd = text.indexOf('.');
            let title = firstSentenceEnd > 0 ? 
                        text.substring(0, firstSentenceEnd > 30 ? 30 : firstSentenceEnd).trim() : 
                        mode.charAt(0).toUpperCase() + mode.slice(1) + " Notes";
            if (title.length < 10) title = mode.charAt(0).toUpperCase() + mode.slice(1) + " Notes";
            
            // Split text into sentences for further processing
            const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
            
            // Identify potential sections or topics
            const topics = identifyTopics(sentences);
            
            // Generate notes based on mode and style
            let notes = '';
            
            switch (mode) {
                case 'lecture':
                    if (style === 'concise') {
                        notes = generateConciseLectureNotes(title, sentences, topics);
                    } else if (style === 'bullet-points') {
                        notes = generateBulletPointLectureNotes(title, sentences, topics);
                    } else if (style === 'question-answer') {
                        notes = generateQALectureNotes(title, sentences, topics);
                    } else { // comprehensive
                        notes = generateComprehensiveLectureNotes(title, sentences, topics);
                    }
                    break;
                    
                case 'discussion':
                    if (style === 'concise') {
                        notes = generateConciseDiscussionNotes(title, sentences, topics);
                    } else if (style === 'bullet-points') {
                        notes = generateBulletPointDiscussionNotes(title, sentences, topics);
                    } else if (style === 'question-answer') {
                        notes = generateQADiscussionNotes(title, sentences, topics);
                    } else { // comprehensive
                        notes = generateComprehensiveDiscussionNotes(title, sentences, topics);
                    }
                    break;
                    
                case 'meeting':
                    if (style === 'concise') {
                        notes = generateConciseMeetingNotes(title, sentences, topics);
                    } else if (style === 'bullet-points') {
                        notes = generateBulletPointMeetingNotes(title, sentences, topics);
                    } else if (style === 'question-answer') {
                        notes = generateQAMeetingNotes(title, sentences, topics);
                    } else { // comprehensive
                        notes = generateComprehensiveMeetingNotes(title, sentences, topics);
                    }
                    break;
            }
            
            // Add highlighting if enabled
            if (highlight) {
                notes = addHighlighting(notes, mode);
            }
            
            return notes;
        }
        
        // Helper function to identify potential topics from sentences
        function identifyTopics(sentences) {
            const topics = [];
            const commonStarters = [
                "first", "second", "third", "next", "finally", "lastly", 
                "to begin", "in conclusion", "moving on", "let's discuss",
                "turning to", "looking at", "considering", "regarding",
                "let me", "i want to", "we should", "key point", "important"
            ];
            
            sentences.forEach(sentence => {
                const lowerSentence = sentence.toLowerCase().trim();
                
                // Check if sentence starts with a common topic introducer
                for (const starter of commonStarters) {
                    if (lowerSentence.startsWith(starter)) {
                        // Remove the starter and clean up
                        let topic = sentence.substring(starter.length).trim();
                        if (topic.startsWith(",")) topic = topic.substring(1).trim();
                        
                        if (topic.length > 0) {
                            topics.push({
                                text: topic,
                                type: determineTopicType(lowerSentence, starter)
                            });
                            break;
                        }
                    }
                }
                
                // Check for questions which might indicate topics
                if (lowerSentence.includes("?") || 
                    lowerSentence.startsWith("what") || 
                    lowerSentence.startsWith("how") ||
                    lowerSentence.startsWith("why")) {
                    topics.push({
                        text: sentence,
                        type: "question"
                    });
                }
            });
            
            return topics;
        }
        
        // Determine what type of topic we're dealing with
        function determineTopicType(sentence, starter) {
            if (starter.includes("first") || starter.includes("second") || starter.includes("third")) {
                return "sequential";
            } else if (starter.includes("conclusion") || starter.includes("finally") || starter.includes("lastly")) {
                return "conclusion";
            } else if (starter.includes("begin") || starter.includes("let's discuss") || starter.includes("turning to")) {
                return "introduction";
            } else if (sentence.includes("important") || sentence.includes("key") || sentence.includes("critical")) {
                return "key_point";
            } else {
                return "general";
            }
        }
        
        // Generate concise lecture notes
        function generateConciseLectureNotes(title, sentences, topics) {
            let notes = `<h3>${title}</h3>\n<p>Key points:</p>\n<ul>`;
            
            // If we have identified topics, use them
            if (topics.length > 0) {
                topics.forEach(topic => {
                    notes += `\n<li>${topic.text}</li>`;
                });
            } else {
                // Otherwise extract key points from sentences
                const keyPoints = extractKeyPoints(sentences, 3);
                keyPoints.forEach(point => {
                    notes += `\n<li>${point}</li>`;
                });
            }
            
            notes += '\n</ul>';
            return notes;
        }
        
        // Extract key points from sentences
        function extractKeyPoints(sentences, count) {
            // Simple implementation: pick sentences with important-looking words
            const importantWords = [
                "important", "key", "critical", "significant", "essential",
                "fundamental", "crucial", "primary", "major", "central"
            ];
            
            const points = [];
            
            // First pass: look for sentences with important words
            for (const sentence of sentences) {
                const lowerSentence = sentence.toLowerCase();
                for (const word of importantWords) {
                    if (lowerSentence.includes(word)) {
                        points.push(sentence);
                        break;
                    }
                }
                
                if (points.length >= count) break;
            }
            
            // Second pass: if we don't have enough points, pick some sentences
            // based on length and position
            if (points.length < count) {
                // Sort remaining sentences by length (longer often have more info)
                const remaining = sentences.filter(s => !points.includes(s))
                    .sort((a, b) => b.length - a.length);
                
                // Add the longest remaining sentences until we reach count
                for (const sentence of remaining) {
                    if (sentence.length > 20) { // Minimum length threshold
                        points.push(sentence);
                    }
                    
                    if (points.length >= count) break;
                }
            }
            
            return points;
        }
        
        // Generate bullet point lecture notes
        function generateBulletPointLectureNotes(title, sentences, topics) {
            let notes = `<h3>${title}</h3>\n<ul>`;
            
            // If we have identified topics, organize by topics
            if (topics.length > 0) {
                // Group topics by type
                const introTopics = topics.filter(t => t.type === "introduction");
                const keyTopics = topics.filter(t => t.type === "key_point");
                const sequentialTopics = topics.filter(t => t.type === "sequential");
                const conclusionTopics = topics.filter(t => t.type === "conclusion");
                const otherTopics = topics.filter(t => !["introduction", "key_point", "sequential", "conclusion"].includes(t.type));
                
                // Add introduction topics
                if (introTopics.length > 0) {
                    notes += `\n<li>Introduction:`;
                    notes += `\n  <ul>`;
                    introTopics.forEach(topic => {
                        notes += `\n    <li>${topic.text}</li>`;
                    });
                    notes += `\n  </ul>`;
                    notes += `\n</li>`;
                } else {
                    notes += `\n<li>Introduction to the topic</li>`;
                }
                
                // Add main content topics
                if (keyTopics.length > 0 || sequentialTopics.length > 0 || otherTopics.length > 0) {
                    notes += `\n<li>Main concepts:`;
                    notes += `\n  <ul>`;
                    
                    // Add key points first
                    keyTopics.forEach(topic => {
                        notes += `\n    <li>${topic.text}</li>`;
                    });
                    
                    // Add sequential topics
                    sequentialTopics.forEach(topic => {
                        notes += `\n    <li>${topic.text}</li>`;
                    });
                    
                    // Add other topics
                    otherTopics.forEach(topic => {
                        notes += `\n    <li>${topic.text}</li>`;
                    });
                    
                    notes += `\n  </ul>`;
                    notes += `\n</li>`;
                } else {
                    notes += `\n<li>Main concepts discussed</li>`;
                }
                
                // Add conclusion topics
                if (conclusionTopics.length > 0) {
                    notes += `\n<li>Conclusion:`;
                    notes += `\n  <ul>`;
                    conclusionTopics.forEach(topic => {
                        notes += `\n    <li>${topic.text}</li>`;
                    });
                    notes += `\n  </ul>`;
                    notes += `\n</li>`;
                } else {
                    notes += `\n<li>Summary of key takeaways</li>`;
                }
            } else {
                // Default structure if no topics identified
                notes += `
<li>Introduction to the topic</li>
<li>Theoretical background</li>
<li>Main concepts:
  <ul>
    <li>${extractKeyPoints(sentences, 1)[0] || 'Primary elements'}</li>
    <li>${sentences.length > 5 ? sentences[Math.floor(sentences.length / 2)] : 'Secondary factors'}</li>
    <li>${sentences.length > 10 ? sentences[sentences.length - 3] : 'Relationships between components'}</li>
  </ul>
</li>
<li>Applications and examples</li>
<li>Summary of key takeaways</li>`;
            }
            
            notes += '\n</ul>';
            return notes;
        }
        
        // Generate question-answer lecture notes
        function generateQALectureNotes(title, sentences, topics) {
            let notes = `<h3>${title}</h3>`;
            
            // Add question about main topic
            notes += `\n<p><strong>Q: What is the main topic of the lecture?</strong></p>`;
            notes += `\n<p>A: The lecture focuses on ${title.toLowerCase()}.</p>`;
            
            // Add question about key components
            notes += `\n<p><strong>Q: What are the key components discussed?</strong></p>`;
            
            if (topics.length > 0) {
                const keyTopics = topics.filter(t => t.type === "key_point" || t.type === "sequential");
                if (keyTopics.length > 0) {
                    notes += `\n<p>A: The lecture covers `;
                    keyTopics.forEach((topic, index) => {
                        if (index > 0) {
                            notes += index === keyTopics.length - 1 ? ' and ' : ', ';
                        }
                        notes += topic.text.toLowerCase();
                    });
                    notes += '.</p>';
                } else {
                    notes += `\n<p>A: The lecture covers several concepts related to ${title.toLowerCase()}.</p>`;
                }
            } else {
                notes += `\n<p>A: The lecture covers theoretical frameworks, methodologies, and practical applications.</p>`;
            }
            
            // Add question about broader implications
            notes += `\n<p><strong>Q: How does this relate to the broader field?</strong></p>`;
            
            // Look for sentences that might discuss broader implications
            let implicationSentence = '';
            for (const sentence of sentences) {
                if (sentence.toLowerCase().includes('impact') || 
                    sentence.toLowerCase().includes('implication') || 
                    sentence.toLowerCase().includes('significance') ||
                    sentence.toLowerCase().includes('relation')) {
                    implicationSentence = sentence;
                    break;
                }
            }
            
            if (implicationSentence) {
                notes += `\n<p>A: ${implicationSentence}</p>`;
            } else {
                notes += `\n<p>A: This topic connects to larger concepts within the discipline and has real-world implications.</p>`;
            }
            
            return notes;
        }
        
        // Generate comprehensive lecture notes
        function generateComprehensiveLectureNotes(title, sentences, topics) {
            let notes = `<h3>${title}</h3>`;
            
            // Introduction section
            notes += `\n<p>`;
            if (sentences.length > 0) {
                notes += sentences[0];
                if (sentences.length > 1) {
                    notes += ' ' + sentences[1];
                }
            } else {
                notes += `The lecture begins with an introduction to ${title.toLowerCase()}, establishing the context and importance of the topic.`;
            }
            notes += `</p>`;
            
            // Key Concepts section
            notes += `\n<h4>Key Concepts</h4>`;
            notes += `\n<ul>`;
            
            if (topics.length > 0) {
                // Filter for topics that are likely key concepts
                const conceptTopics = topics.filter(t => 
                    t.type === "key_point" || 
                    t.type === "sequential" || 
                    t.type === "general"
                );
                
                if (conceptTopics.length > 0) {
                    conceptTopics.forEach(topic => {
                        notes += `\n<li>${topic.text}</li>`;
                    });
                } else {
                    // Fall back to extracting key points
                    const keyPoints = extractKeyPoints(sentences, 3);
                    keyPoints.forEach(point => {
                        notes += `\n<li>${point}</li>`;
                    });
                }
            } else {
                // Fall back to extracting key points
                const keyPoints = extractKeyPoints(sentences, 3);
                keyPoints.forEach(point => {
                    notes += `\n<li>${point}</li>`;
                });
            }
            
            notes += `\n</ul>`;
            
            // Important Relationships section
            notes += `\n<h4>Important Relationships</h4>`;
            notes += `\n<p>`;
            
            // Look for sentences discussing relationships
            let relationshipSentence = '';
            for (const sentence of sentences) {
                if (sentence.toLowerCase().includes('relationship') || 
                    sentence.toLowerCase().includes('connection') || 
                    sentence.toLowerCase().includes('between') ||
                    sentence.toLowerCase().includes('correlate')) {
                    relationshipSentence = sentence;
                    break;
                }
            }
            
            if (relationshipSentence) {
                notes += relationshipSentence;
            } else {
                notes += `The relationships between these concepts are explored, with emphasis on how they interact in various contexts.`;
            }
            notes += `</p>`;
            
            // Examples & Applications section
            notes += `\n<h4>Examples & Applications</h4>`;
            notes += `\n<p>`;
            
            // Look for sentences discussing examples
            let exampleSentence = '';
            for (const sentence of sentences) {
                if (sentence.toLowerCase().includes('example') || 
                    sentence.toLowerCase().includes('instance') || 
                    sentence.toLowerCase().includes('case study') ||
                    sentence.toLowerCase().includes('illustration')) {
                    exampleSentence = sentence;
                    break;
                }
            }
            
            if (exampleSentence) {
                notes += exampleSentence;
            } else {
                notes += `Several examples are provided to illustrate the practical implementation of these ideas.`;
            }
            notes += `</p>`;
            
            // Conclusion section
            notes += `\n<h4>Conclusion</h4>`;
            notes += `\n<p>`;
            
            // Look for conclusion topics or sentences
            const conclusionTopics = topics.filter(t => t.type === "conclusion");
            if (conclusionTopics.length > 0) {
                conclusionTopics.forEach((topic, index) => {
                    if (index > 0) notes += ' ';
                    notes += topic.text;
                });
            } else if (sentences.length > 3) {
                // Use the last sentence as conclusion
                notes += sentences[sentences.length - 1];
            } else {
                notes += `The lecture concludes by summarizing the key points and suggesting future directions for exploration.`;
            }
            notes += `</p>`;
            
            return notes;
        }
        
        // Generate discussion notes (simplified implementations)
        function generateConciseDiscussionNotes(title, sentences, topics) {
            let notes = `<h3>${title}</h3>\n<p>Main discussion points:</p>\n<ul>`;
            
            // Extract key discussion points
            const keyPoints = extractKeyPoints(sentences, 3);
            keyPoints.forEach(point => {
                notes += `\n<li>${point}</li>`;
            });
            
            notes += '\n</ul>';
            return notes;
        }
        
        function generateBulletPointDiscussionNotes(title, sentences, topics) {
            return `<h3>${title}</h3>
<ul>
<li>Topic introduction</li>
<li>Viewpoint 1: Supporting arguments</li>
<li>Viewpoint 2: Counterarguments</li>
<li>Questions raised:
  <ul>
    <li>Methodological concerns</li>
    <li>Practical implications</li>
    <li>Theoretical foundations</li>
  </ul>
</li>
<li>Areas of consensus</li>
<li>Unresolved points</li>
</ul>`;
        }
        
        function generateQADiscussionNotes(title, sentences, topics) {
            return `<h3>${title}</h3>
<p><strong>Q: What was the main topic of discussion?</strong></p>
<p>A: The discussion centered on ${title.toLowerCase()}.</p>
<p><strong>Q: What were the different perspectives presented?</strong></p>
<p>A: Multiple viewpoints were shared, including theoretical considerations and practical applications.</p>
<p><strong>Q: What questions remained unresolved?</strong></p>
<p>A: Some questions about methodology and long-term implications remained open for further discussion.</p>`;
        }
        
        function generateComprehensiveDiscussionNotes(title, sentences, topics) {
            return `<h3>${title}</h3>
<p>The discussion began with an overview of ${title.toLowerCase()}, with participants sharing their initial thoughts on the topic.</p>
<h4>Different Perspectives</h4>
<ul>
<li>Perspective A: Focus on theoretical implications</li>
<li>Perspective B: Emphasis on practical applications</li>
<li>Perspective C: Consideration of ethical dimensions</li>
</ul>
<h4>Key Questions Raised</h4>
<p>Several important questions emerged during the discussion:</p>
<ul>
<li>How can these ideas be implemented effectively?</li>
<li>What are the potential limitations or drawbacks?</li>
<li>How do these concepts relate to existing frameworks?</li>
</ul>
<h4>Areas of Consensus</h4>
<p>Participants generally agreed on several fundamental points while acknowledging areas requiring further exploration.</p>
<h4>Action Items</h4>
<p>The discussion concluded with suggestions for further research and follow-up discussions.</p>`;
        }
        
        // Generate meeting notes (simplified implementations)
        function generateConciseMeetingNotes(title, sentences, topics) {
            let notes = `<h3>${title}</h3>\n<p>Meeting summary:</p>\n<ul>`;
            
            // Extract key meeting points
            const keyPoints = extractKeyPoints(sentences, 3);
            keyPoints.forEach(point => {
                notes += `\n<li>${point}</li>`;
            });
            
            notes += '\n</ul>';
            return notes;
        }
        
        function generateBulletPointMeetingNotes(title, sentences, topics) {
            return `<h3>${title}</h3>
<ul>
<li>Agenda overview</li>
<li>Updates:
  <ul>
    <li>Project status reports</li>
    <li>Budget considerations</li>
    <li>Timeline adjustments</li>
  </ul>
</li>
<li>Decisions made</li>
<li>Action items:
  <ul>
    <li>Task assignments</li>
    <li>Deadlines set</li>
    <li>Follow-up responsibilities</li>
  </ul>
</li>
<li>Next meeting details</li>
</ul>`;
        }
        
        function generateQAMeetingNotes(title, sentences, topics) {
            return `<h3>${title}</h3>
<p><strong>Q: What was the purpose of the meeting?</strong></p>
<p>A: The meeting addressed ${title.toLowerCase()} and related project considerations.</p>
<p><strong>Q: What decisions were made?</strong></p>
<p>A: Decisions included project priorities, resource allocation, and timeline adjustments.</p>
<p><strong>Q: What are the next steps?</strong></p>
<p>A: Action items were assigned to team members with specific deadlines for completion.</p>`;
        }
        
        function generateComprehensiveMeetingNotes(title, sentences, topics) {
            return `<h3>${title}</h3>
<p>The meeting opened with a review of the agenda and previous action items. Participants then shared updates on their respective areas.</p>
<h4>Updates</h4>
<ul>
<li>Project Status: Current progress and challenges</li>
<li>Budget Review: Financial considerations and projections</li>
<li>Timeline Assessment: Evaluation of project milestones</li>
</ul>
<h4>Key Discussions</h4>
<p>The team discussed several important topics, weighing options and considering implications.</p>
<h4>Decisions Made</h4>
<ul>
<li>Decision 1: Adjustment to project scope</li>
<li>Decision 2: Resource allocation changes</li>
<li>Decision 3: Approval of new approach</li>
</ul>
<h4>Action Items</h4>
<ul>
<li>Team Member A: Complete task X by date</li>
<li>Team Member B: Research options for Y</li>
<li>Team Member C: Coordinate with stakeholders on Z</li>
</ul>
<h4>Next Meeting</h4>
<p>The next meeting is scheduled for [date/time] with a focus on [topic].</p>`;
        }
        
        // Add highlighting to notes
        function addHighlighting(notes, mode) {
            // Define key terms based on the selected mode
            let potentialTerms = [];
            
            switch (mode) {
                case 'lecture':
                    potentialTerms = ['theory', 'concept', 'method', 'analysis', 'research', 'data', 'model', 
                                    'framework', 'structure', 'function', 'process', 'system', 'development',
                                    'application', 'example'];
                    break;
                case 'discussion':
                    potentialTerms = ['perspective', 'viewpoint', 'argument', 'question', 'debate', 'consensus', 
                                    'disagreement', 'evidence', 'implication', 'consideration', 'critique',
                                    'response', 'interpretation', 'clarification'];
                    break;
                case 'meeting':
                    potentialTerms = ['agenda', 'update', 'decision', 'action item', 'deadline', 'responsibility', 
                                    'timeline', 'budget', 'resource', 'stakeholder', 'milestone', 'objective',
                                    'priority', 'status', 'follow-up'];
                    break;
            }
            
            // Highlight these terms in the notes
            potentialTerms.forEach(term => {
                const regex = new RegExp(`\\b${term}\\b`, 'gi');
                notes = notes.replace(regex, `<span class="highlight">$&</span>`);
            });
            
            return notes;
        }

        // Handle speaker identification
        function processSpeakerSegment(text, speaker) {
            if (!speaker && (!speakerProfiles || !speakerProfiles.length)) {
                return; // No enrolled speakers
            }
            
            // If no specific speaker provided, identify the most likely speaker
            if (!speaker && speakerProfiles.length > 0) {
                // In a real implementation, this would use the Eagle model
                // For demo, we'll pick a random enrolled speaker
                const speakerIndex = Math.floor(Math.random() * speakerProfiles.length);
                speaker = speakerProfiles[speakerIndex];
            }
            
            // Create a new speaker segment element
            const speakerItem = document.createElement('li');
            speakerItem.className = 'speaker-item';
            speakerItem.innerHTML = `
                <div class="speaker-avatar">${speaker.name.charAt(0).toUpperCase()}</div>
                <div class="speaker-text">
                    <div class="speaker-name">${speaker.name}</div>
                    <div class="speaker-segment">${text}</div>
                </div>
            `;
            
            // Add to the speaker list
            speakerList.appendChild(speakerItem);
            
            // Scroll to the bottom
            const container = speakerList.parentElement;
            container.scrollTop = container.scrollHeight;
        }

        // Initialize speaker recognition (using actual Picovoice Eagle)
        async function initSpeakerRecognition() {
            try {
                // In a real implementation, this would initialize the Eagle SDK with proper keys
                console.log('Speaker recognition initialized');
                return true;
            } catch (error) {
                console.error('Error initializing speaker recognition:', error);
                return false;
            }
        }

        // Start speaker enrollment
        async function startEnrollment() {
            if (isEnrolling) return;
            
            const speakerName = document.getElementById('speaker-name').value.trim();
            if (!speakerName) {
                alert('Please enter a speaker name');
                return;
            }
            
            // Reset progress
            currentEnrollmentPercentage = 0;
            enrollmentProgress.style.width = '0%';
            enrollmentStatus.textContent = 'Starting enrollment...';
            
            try {
                // Get microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                
                // In a real implementation, this would use the Eagle SDK for enrollment
                // For the demo, we'll simulate enrollment
                isEnrolling = true;
                updateEnrollmentUI(true);
                
                // In a real app, we would collect audio and process it with Eagle
                // Here we'll simulate the progress
                const enrollmentInterval = setInterval(() => {
                    currentEnrollmentPercentage += 5;
                    if (currentEnrollmentPercentage > 100) {
                        currentEnrollmentPercentage = 100;
                        clearInterval(enrollmentInterval);
                        stream.getTracks().forEach(track => track.stop());
                        enrollmentStatus.textContent = 'Enrollment complete!';
                        updateEnrollmentUI(false);
                        isEnrolling = false;
                        saveProfileBtn.disabled = false;
                    }
                    
                    enrollmentProgress.style.width = currentEnrollmentPercentage + '%';
                    enrollmentStatus.textContent = `Enrollment progress: ${currentEnrollmentPercentage}%`;
                }, 200);
            } catch (error) {
                console.error('Error starting enrollment:', error);
                enrollmentStatus.textContent = 'Error: ' + error.message;
                isEnrolling = false;
                updateEnrollmentUI(false);
            }
        }

        // Stop speaker enrollment
        function stopEnrollment() {
            if (!isEnrolling) return;
            
            isEnrolling = false;
            updateEnrollmentUI(false);
            enrollmentStatus.textContent = 'Enrollment stopped at ' + currentEnrollmentPercentage + '%';
            
            if (currentEnrollmentPercentage >= 100) {
                saveProfileBtn.disabled = false;
            }
        }

        // Update enrollment UI
        function updateEnrollmentUI(isActive) {
            if (isActive) {
                startEnrollmentBtn.disabled = true;
                stopEnrollmentBtn.disabled = false;
                document.getElementById('speaker-name').disabled = true;
            } else {
                startEnrollmentBtn.disabled = false;
                stopEnrollmentBtn.disabled = true;
                document.getElementById('speaker-name').disabled = false;
            }
        }

        // Save speaker profile
        function saveProfile() {
            const speakerName = document.getElementById('speaker-name').value.trim();
            if (!speakerName || currentEnrollmentPercentage < 100) return;
            
            // Create a profile object
            const profile = {
                name: speakerName,
                // In a real implementation, this would contain the actual speaker profile data
                enrollmentDate: new Date().toISOString(),
                id: 'speaker_' + Date.now()
            };
            
            // Add to profiles
            speakerProfiles.push(profile);
            
            // Add to enrolled speakers list
            const speakerItem = document.createElement('li');
            speakerItem.className = 'speaker-item';
            speakerItem.innerHTML = `
                <div class="speaker-avatar">${speakerName.charAt(0).toUpperCase()}</div>
                <div class="speaker-text">
                    <div class="speaker-name">${speakerName}</div>
                    <div class="speaker-segment">Speaker profile saved</div>
                </div>
            `;
            enrolledSpeakersList.appendChild(speakerItem);
            
            // Reset enrollment
            currentEnrollmentPercentage = 0;
            enrollmentProgress.style.width = '0%';
            enrollmentStatus.textContent = 'Ready to enroll';
            document.getElementById('speaker-name').value = '';
            saveProfileBtn.disabled = true;
            
            // Update UI based on speaker profiles
            updateSpeakerUI();
        }

        // Update UI based on speaker profiles
        function updateSpeakerUI() {
            if (speakerProfiles.length > 0 && (currentMode === 'discussion' || currentMode === 'meeting')) {
                speakerSection.style.display = 'block';
            } else {
                speakerSection.style.display = 'none';
            }
        }

        // Download notes
        downloadNotesBtn.addEventListener('click', function() {
            const notesContent = notesText.innerHTML;
            const blob = new Blob([`<html><head><title>LectureNotes - ${currentMode.charAt(0).toUpperCase() + currentMode.slice(1)} Notes</title><style>
                body { font-family: Arial, sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px; }
                h3 { color: #4F46E5; }
                .highlight { background-color: #EEF2FF; color: #4F46E5; padding: 0 3px; border-radius: 3px; }
            </style></head><body>${notesContent}</body></html>`], { type: 'text/html' });
            
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `${currentMode}-notes.html`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        });

        // Regenerate notes
        regenerateBtn.addEventListener('click', function() {
            if (transcript) {
                generateNotes(true);
            }
        });

        // Tab switching
        tabs.forEach(tab => {
            tab.addEventListener('click', function() {
                const tabContainer = this.closest('.tab-container');
                const activeTab = tabContainer.querySelector('.active');
                activeTab.classList.remove('active');
                this.classList.add('active');
                
                // In a real implementation, this would switch content based on the tab
            });
        });

        // Mode switching
        modeBtns.forEach(btn => {
            btn.addEventListener('click', function() {
                const activeBtn = document.querySelector('.mode-btn.active');
                activeBtn.classList.remove('active');
                this.classList.add('active');
                
                currentMode = this.getAttribute('data-mode');
                
                // Update UI based on selected mode
                updateSpeakerUI();
                
                // Regenerate notes if transcript exists
                if (transcript && transcript.trim() !== '') {
                    generateNotes(true);
                } else {
                    notesText.innerHTML = `
                        <p>When you start recording, intelligent notes will be generated here based on the content.</p>
                        <p>You're in <strong>${currentMode} mode</strong>. Notes will be organized accordingly.</p>
                    `;
                }
            });
        });

        // Show/hide settings section
        settingsButton.addEventListener('click', function() {
            const settingsSection = document.querySelector('.settings-section');
            settingsSection.style.display = settingsSection.style.display === 'none' ? 'block' : 'none';
        });

        // Dark mode toggle
        themeToggle.addEventListener('click', function() {
            document.body.classList.toggle('dark-mode');
            const icon = themeToggle.querySelector('i');
            if (icon.classList.contains('fa-moon')) {
                icon.classList.remove('fa-moon');
                icon.classList.add('fa-sun');
                themeToggle.querySelector('span').textContent = 'Light Mode';
            } else {
                icon.classList.remove('fa-sun');
                icon.classList.add('fa-moon');
                themeToggle.querySelector('span').textContent = 'Dark Mode';
            }
        });

        // Speaker setup button
        speakerSetupBtn.addEventListener('click', function() {
            enrollmentModal.style.display = 'block';
        });

        // Close modal
        closeModalBtn.addEventListener('click', function() {
            enrollmentModal.style.display = 'none';
        });

        // Click outside modal to close
        window.addEventListener('click', function(event) {
            if (event.target === enrollmentModal) {
                enrollmentModal.style.display = 'none';
            }
        });

        // Start recording button
        startRecordingBtn.addEventListener('click', function() {
            if (!isRecording) {
                startRecording();
            }
        });

        // Stop recording button
        stopRecordingBtn.addEventListener('click', stopRecording);

        // Start enrollment button
        startEnrollmentBtn.addEventListener('click', startEnrollment);

        // Stop enrollment button
        stopEnrollmentBtn.addEventListener('click', stopEnrollment);

        // Save profile button
        saveProfileBtn.addEventListener('click', saveProfile);

        // Language select change
        document.getElementById('language-select').addEventListener('change', function() {
            if (recognition) {
                recognition.lang = this.value;
            }
        });

        // Initialize on load
        document.addEventListener('DOMContentLoaded', function() {
            // Initialize settings display
            document.querySelector('.settings-section').style.display = 'none';
            
            // Hide speaker section initially
            speakerSection.style.display = 'none';
            
            // Initialize audio recording capabilities
            const recordingAvailable = initializeAudioRecording();
            if (!recordingAvailable) {
                // If no recording methods are available, disable the start button
                startRecordingBtn.disabled = true;
            }
            
            // Initialize speaker recognition
            initSpeakerRecognition();
        });
    </script>
</body>
</html>
